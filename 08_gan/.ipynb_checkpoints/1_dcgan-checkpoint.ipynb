{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afdac0e489ea9a36f68ff82ebeefaff1",
     "grade": false,
     "grade_id": "cell-3941e0c28ecf711b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> May 4, 2022 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 1. Generative adversarial networks (GANs). DCGAN: Deep convolutional GAN\n",
    "\n",
    "The goal of this exercise is to get familiar with generative adversarial networks and specifically DCGAN. The model was proposed by [Radford et al., 2015](https://arxiv.org/pdf/1511.06434.pdf).\n",
    "\n",
    "DCGAN is probably the simplest GAN model which is relatively easy to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98d57e95bab744702a07e57404aa169b",
     "grade": true,
     "grade_id": "cell-bd68b7386e29d846",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd275621253cd028c5065035e3390f93",
     "grade": false,
     "grade_id": "cell-2212a6a282e966a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04ce3d7c3c2e4c327a34405291398340",
     "grade": false,
     "grade_id": "cell-140f604a5cb368f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use MNIST data in this exercise. **Note that we re-scale images so that the pixel intensities are in the range [-1, 1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57252aa059b4324485613a29450837d",
     "grade": false,
     "grade_id": "cell-55039c5db5aa5d3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 100\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceff023afd66794411ec51227791aa54",
     "grade": false,
     "grade_id": "cell-797591c879634741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Generative adversarial networks\n",
    "\n",
    "Our task is to train a generative model of the data, that is a model from which we can draw samples that will have a distribution similar to the distribution of the training data (MNIST digits in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9017381ae18064c6b3dc34b1e836e7c3",
     "grade": false,
     "grade_id": "cell-9356f4dc68bfdc4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generative model that we are going to train is:\n",
    "\\begin{align}\n",
    "z &\\sim N(0, I)\n",
    "\\\\\n",
    "x &= g(z)\n",
    "\\end{align}\n",
    "that is the data is generated by applying a nonlinear transformation to samples drawn from the standard normal distribution.\n",
    "\n",
    "We are going to model $g$ with a deep neural network created below. In DCGAN, the generator is made of only transposed convolutional layers `ConvTranspose2d`.\n",
    "The proposed architecture for the generator:\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `4*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `nc` output channels, no bias,\n",
    "   followed by `tanh`.\n",
    "\n",
    "The `tanh` nonlinearity guarantees that the output is between -1 and 1 which holds for our scaling of the training data.\n",
    "\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description above is not full. To get the correct output shape, you need to set correctly other parameters of the `ConvTranspose2d` layers. Note that training may fail for some padding schemes. If training fails but everything else looks correct, try changing the padding scheme.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a26a1e9624ea328d6bdc50a403e96da4",
     "grade": false,
     "grade_id": "Generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=10, ngf=64, nc=1):\n",
    "        \"\"\"GAN generator.\n",
    "        \n",
    "        Args:\n",
    "          nz:  Number of elements in the latent code.\n",
    "          ngf: Base size (number of channels) of the generator layers.\n",
    "          nc:  Number of channels in the generated images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, 4 * ngf, kernel_size=4, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(4 * ngf),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(4 * ngf, 2 * ngf, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(2 * ngf),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(2 * ngf, ngf, kernel_size=4, stride=2, bias=False, padding=2),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(ngf, nc, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z, verbose=False):\n",
    "        \"\"\"Generate images by transforming the given noise tensor.\n",
    "        \n",
    "        Args:\n",
    "          z of shape (batch_size, nz, 1, 1): Tensor of noise samples. We use the last two singleton dimensions\n",
    "                          so that we can feed z to the generator without reshaping.\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, nc, 28, 28): Generated images.\n",
    "        \"\"\"\n",
    "        out = self.model(z)\n",
    "        if verbose:\n",
    "            print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80ee06fd8f120e253712503ca8dcbea",
     "grade": false,
     "grade_id": "cell-65fe5c0af77b5d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.8690, -0.3592, -0.8915,  ...,  0.5870, -0.3680, -0.3370],\n",
      "          [-0.3454,  0.8548, -0.4502,  ...,  0.1905,  0.2265,  0.7529],\n",
      "          [-0.1932, -0.9579,  0.5128,  ..., -0.5587, -0.0022, -0.1666],\n",
      "          ...,\n",
      "          [-0.3879,  0.5933, -0.3250,  ...,  0.1646, -0.7753, -0.1815],\n",
      "          [-0.5911, -0.9115, -0.4051,  ..., -0.6271, -0.4464, -0.7274],\n",
      "          [-0.8201,  0.7918, -0.7021,  ...,  0.7703, -0.4020,  0.5868]]],\n",
      "\n",
      "\n",
      "        [[[-0.4606, -0.6812, -0.2930,  ..., -0.4400, -0.9467, -0.6603],\n",
      "          [-0.6135, -0.5548,  0.3155,  ...,  0.3960, -0.4137, -0.0088],\n",
      "          [ 0.3842, -0.6662,  0.1087,  ..., -0.9809, -0.6859,  0.4428],\n",
      "          ...,\n",
      "          [-0.5890, -0.5481,  0.8975,  ..., -0.0903, -0.3661,  0.0419],\n",
      "          [ 0.3608, -0.9167, -0.5171,  ..., -0.9720,  0.8640, -0.6736],\n",
      "          [-0.4039,  0.8516, -0.8777,  ...,  0.9738, -0.7826,  0.0239]]],\n",
      "\n",
      "\n",
      "        [[[-0.7674, -0.8670, -0.6626,  ..., -0.3796, -0.8604, -0.5611],\n",
      "          [ 0.5183,  0.5048, -0.0462,  ..., -0.7929,  0.4909, -0.7617],\n",
      "          [ 0.1992, -0.7842, -0.1721,  ..., -0.7373, -0.8813, -0.2107],\n",
      "          ...,\n",
      "          [ 0.0915,  0.4149, -0.6331,  ..., -0.6949, -0.5843,  0.6538],\n",
      "          [-0.5809, -0.9740, -0.1377,  ..., -0.7664,  0.3043, -0.8935],\n",
      "          [-0.3194,  0.9392, -0.7576,  ...,  0.9420, -0.6467, -0.4190]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.8068, -0.9509, -0.9675,  ..., -0.8425, -0.8337,  0.1116],\n",
      "          [-0.7938,  0.5050,  0.8481,  ..., -0.7311, -0.1937,  0.7603],\n",
      "          [-0.3474, -0.4268, -0.9779,  ..., -0.6423, -0.1090, -0.5718],\n",
      "          ...,\n",
      "          [-0.9888,  0.4879, -0.2864,  ...,  0.5852, -0.7554,  0.8296],\n",
      "          [ 0.8502, -0.9973, -0.9896,  ..., -0.9982,  0.0652, -0.7723],\n",
      "          [-0.9052,  0.8885, -0.5015,  ...,  0.9903, -0.9496,  0.0057]]],\n",
      "\n",
      "\n",
      "        [[[-0.4652, -0.4673, -0.6599,  ..., -0.8643, -0.7181, -0.5963],\n",
      "          [-0.7655,  0.9875,  0.6148,  ...,  0.5627,  0.0135,  0.9363],\n",
      "          [ 0.3986, -0.9991,  0.4675,  ..., -0.9936,  0.8773, -0.9935],\n",
      "          ...,\n",
      "          [-0.7432,  0.5184,  0.2554,  ...,  0.8513, -0.9948, -0.5545],\n",
      "          [-0.3910, -0.6522, -0.0727,  ..., -0.8962,  0.4030,  0.5549],\n",
      "          [-0.4335,  0.9445, -0.5190,  ...,  0.9582, -0.3466,  0.8821]]],\n",
      "\n",
      "\n",
      "        [[[-0.6425, -0.8084, -0.0642,  ..., -0.9244, -0.3615,  0.2161],\n",
      "          [-0.9712,  0.2767,  0.5857,  ...,  0.9793, -0.4274,  0.9346],\n",
      "          [ 0.8404, -0.7658,  0.1195,  ..., -0.9781,  0.8678, -0.8848],\n",
      "          ...,\n",
      "          [-0.5625,  0.5747,  0.7193,  ...,  0.8613,  0.3740,  0.7894],\n",
      "          [-0.6029, -0.9547, -0.5709,  ..., -0.6566, -0.8149,  0.3757],\n",
      "          [-0.3877,  0.9702, -0.8134,  ...,  0.9887, -0.9559,  0.3549]]]],\n",
      "       grad_fn=<TanhBackward0>)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Generator_shapes():\n",
    "    nz = 10\n",
    "    netG = Generator(nz, ngf=64, nc=1)\n",
    "\n",
    "    batch_size = 32\n",
    "    noise = torch.randn(batch_size, nz, 1, 1)\n",
    "    out = netG(noise, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size, 1, 28, 28]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Generator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5a58be5bcef66ea9316f080270a0e9",
     "grade": false,
     "grade_id": "cell-0151d274de94f50d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the generator\n",
    "\n",
    "The generative model will be guided by a discriminator whose task is to separate (classify) data into two classes:\n",
    "* true data (samples from the training set)\n",
    "* generated data (samples generated by the generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bb6fa5353ab5f0262705a5fea9b38e2",
     "grade": false,
     "grade_id": "cell-3f77648eb2fe0ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c815e41e4de9f630bc1b63ee3089bd4c",
     "grade": false,
     "grade_id": "cell-7f59b33f30149a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The task of the generator is to confuse the discriminator as much as possible, which is the case when the distribution produced by the generator perfectly replicates the data distribution.\n",
    "\n",
    "In the cell below, you need to implement the loss function which is used to train the generator. The loss should be the `binary_cross_entropy` loss computed with `real_label` as targets for the generated samples.\n",
    "\n",
    "**IMPORTANT: Please use the `mean` reduction when computing the loss!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ec1dbae1eb2d04179fcdc7ffe64b0bc",
     "grade": false,
     "grade_id": "generator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(netD, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN generator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator whose forward function takes inputs of shape (batch_size, nc, 28, 28)\n",
    "         and produces outputs of shape (batch_size, 1).\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      loss: The mean of the binary cross-entropy losses computed for all the samples in the batch.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    discr_out = netD(fake_images)\n",
    "    return F.binary_cross_entropy(discr_out, torch.ones_like(discr_out, device = discr_out.device) * real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a59db8f81b28a77cd02b5c3d5eb926cf",
     "grade": true,
     "grade_id": "test_Generator_loss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests generator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2554c161811028fc12e15c5b9738c171",
     "grade": false,
     "grade_id": "cell-63faa114782d7e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Discriminator\n",
    "\n",
    "In DCGAN, the discriminator is a stack of only convolutional layers.\n",
    "\n",
    "The proposed architecture for the discriminator:\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `2*ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `4*ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, 1 output channel, no bias,\n",
    "   followed by `sigmoid`.\n",
    "\n",
    "Notes:\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description is not full, please fill the missing pieces by yourself.**\n",
    "* In this exercise, the discriminator works well without batch normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f7aac6360862eb5f3d3fcdae2277ae6",
     "grade": false,
     "grade_id": "Discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        \"\"\"GAN discriminator.\n",
    "        \n",
    "        Args:\n",
    "          nc:  Number of channels in images.\n",
    "          ndf: Base size (number of channels) of the discriminator layers.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(ndf),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(ndf, 2 * ndf, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(2 * ndf),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(2 * ndf, 4 * ndf, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.BatchNorm2d(4 * ndf),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(4 * ndf, nc, kernel_size=4, stride=2, bias=False, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"Classify given images into real/fake.\n",
    "        \n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Images to be classified.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size,): Probabilities that images are real. All elements should be between 0 and 1.\n",
    "        \"\"\"\n",
    "        out = self.model(x).flatten()\n",
    "        if verbose:\n",
    "            print(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc353b6ac051abe22c8f022a7860c348",
     "grade": false,
     "grade_id": "cell-cef1ff3c74404557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492,\n",
      "        0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492,\n",
      "        0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492, 0.4492,\n",
      "        0.4492, 0.4492, 0.4492, 0.4492, 0.4492],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Discriminator_shapes():\n",
    "    batch_size = 32\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    images = torch.ones(32, 1, 28, 28)\n",
    "    out = netD(images, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Discriminator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6523502226d744a59c86163eee57e75a",
     "grade": false,
     "grade_id": "cell-51681d3003e07996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the discriminator\n",
    "\n",
    "The discriminator is trained to solve a binary classification problem: to separate real data from generated samples. Thus, the output of the discriminator should be a scalar between 0 and 1.\n",
    "\n",
    "You need to implement the loss function used to train the discriminator. The dicriminator uses the `binary_cross_entropy` loss using `real_label` as targets for real samples and `fake_label` as targets for generated samples.\n",
    "\n",
    "**IMPORTANT: Please use the `mean` reduction when computing the loss!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "440db54740e04d60aa69cd1c134691dc",
     "grade": false,
     "grade_id": "discriminator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(netD, real_images, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN discriminator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator.\n",
    "      real_images of shape (batch_size, nc, 28, 28): Real images.\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      d_loss_real: The mean of the binary cross-entropy losses computed on the real_images.\n",
    "      D_real: Mean output of the discriminator for real_images. This is useful for tracking convergence.\n",
    "      d_loss_fake: The mean of the binary cross-entropy losses computed on the fake_images.\n",
    "      D_fake: Mean output of the discriminator for fake_images. This is useful for tracking convergence.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    discr_real = netD(real_images)\n",
    "    discr_fake = netD(fake_images)\n",
    "\n",
    "    d_loss_real = F.binary_cross_entropy(discr_real, torch.ones_like(discr_real, device=discr_real.device) * real_label)\n",
    "    d_loss_fake = F.binary_cross_entropy(discr_fake, torch.ones_like(discr_fake, device=discr_fake.device) * fake_label)\n",
    "    \n",
    "    D_real = discr_real.mean()\n",
    "    D_fake = discr_fake.mean()\n",
    "    return d_loss_real, D_real, d_loss_fake, D_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4029769ed532dff0b85dce6a77184c",
     "grade": true,
     "grade_id": "cell-461f1d2ee56f035d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_discriminator_loss():\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "    real_images = fake_images = torch.ones(32, 1, 28, 28)\n",
    "\n",
    "    d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(netD, real_images, fake_images)\n",
    "    assert d_loss_real.shape == torch.Size([]), \"d_loss_real should be a scalar tensor.\"\n",
    "    assert 0 < D_real < 1, \"D_real should be a scalar between 0 and 1.\"\n",
    "    assert d_loss_fake.shape == torch.Size([]), \"d_loss_fake should be a scalar tensor.\"\n",
    "    assert 0 < D_fake < 1, \"D_fake should be a scalar between 0 and 1.\"\n",
    "    print('Success')\n",
    "\n",
    "test_discriminator_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5d6b90dd61ec79abd9a105af1d4f737",
     "grade": true,
     "grade_id": "test_Discriminator_loss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests discriminator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ce91d7e84c593bcd3eb8568b086cea",
     "grade": false,
     "grade_id": "cell-32a46a6724373e1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Evaluation of quality of generated samples\n",
    "\n",
    "We would like to evaluate the quality of the generated samples using some metric. Designing such a metric is not a trivial task. The most popular metric for assessing the quality of generated images is Fréchet Inception Distance (FID) [(Heusel et al., 2017)](https://arxiv.org/abs/1706.08500). The FID score compares the distribution of intermediate activations when real or generated samples are passed through an Inception network. The Inception network is a specific type of a convolutional neural network that is pre-trained on image classification tasks.\n",
    "\n",
    "In this exercise, we do not generate natural images and therefore we do not use the Inception network to compute the activations. Instead, we use a simple convolutional neural network trained to classify MNIST digits. Therefore, we call the metric FD score (dropping the word *Inception*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f93c4e446fa89f08395d80db52bae206",
     "grade": false,
     "grade_id": "cell-7292f1f13a3359dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FDScore(\n",
       "  (net): Classifier(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (fc1): Linear(in_features=512, out_features=120, bias=True)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fd\n",
    "\n",
    "# Load an FD scorer pre-trained on MNIST\n",
    "fdscore = fd.FDScore.pretrained()\n",
    "fdscore.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe7284b80697efad494a5b4e711827f",
     "grade": false,
     "grade_id": "cell-1b6b5eca75e178fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Gaussian noise: 516.16671\n"
     ]
    }
   ],
   "source": [
    "# Score on uniform noise in the range [-1, 1]\n",
    "samples = torch.rand(10000, 1, 28, 28).to(device)\n",
    "samples = (samples - 0.5) * 2\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on Gaussian noise: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9998ffb799885a60661494c991679147",
     "grade": false,
     "grade_id": "cell-bebdfbe98e8010dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on MNIST: 0.80417\n"
     ]
    }
   ],
   "source": [
    "# Score on real MNIST digits\n",
    "samples = torch.stack([testset[i][0] for i in range(10000)]).to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on MNIST: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ac85d9d8c5eba3ee99bb50564ae4f1d",
     "grade": false,
     "grade_id": "cell-619a00b55e2632b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Training GANs\n",
    "\n",
    "We will now train a GAN. To assess the quality of the generated samples, we will use a simple scorer loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76a80ba0da69e3d29ac875b23c42ba17",
     "grade": false,
     "grade_id": "cell-f306dde125361541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "nz = 10\n",
    "netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "netD = netD.to(device)\n",
    "netG = netG.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec6414cb4c1adc4431eac62b2e8f8eff",
     "grade": false,
     "grade_id": "cell-e5478e8a7afe65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Optimizer of the discriminator: Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "* Optimizer of the generator:     Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "\n",
    "Hints:\n",
    "- We will use the FD score to assess the quality of the generated samples. Your GAN should have the FD score below 10. This level can be reached after 5 epochs. Note that the score is stochastic and it can fluctuate during training. At convergence, the FD score can fluctuate in the range [3, 9].\n",
    "- You can use the following code to track the training progress. The code plots some generated images and computes the score that we use to evaluate the trained model. Note that the images fed to the scorer need to be normalized to be in the range [-1, 1].\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    # Plot generated images\n",
    "    z = torch.randn(144, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples)\n",
    "    \n",
    "    # Compute score\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    score = fdscore.calculate(samples)\n",
    "```\n",
    "- You can track `D_real` and `D_fake` returned by function `discriminator_loss()`. When it is hard for the discriminator to separate real and fake images, their values are close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae914389933e3986497ab27451391731",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     optimizer_g\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     24\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m generator_loss(netD, images_gen)\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     optimizer_g\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Plot generated images\u001b[39;00m\n",
      "File \u001b[0;32m/opt/software/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/software/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    \n",
    "    optimizer_d = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_g = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "#             images = (images - images.min()) * 2/(images.max() - images.min())  - 1\n",
    "            \n",
    "            z = torch.randn(144, nz, 1, 1, device=device)\n",
    "            \n",
    "            images_gen = netG(z)\n",
    "            \n",
    "            d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(netD, images, images_gen.detach())\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            optimizer_g.zero_grad()\n",
    "            \n",
    "            g_loss = generator_loss(netD, images_gen)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            \n",
    "            optimizer_g.step()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Plot generated images\n",
    "            z = torch.randn(144, nz, 1, 1, device=device)\n",
    "            samples = netG(z)\n",
    "            tools.plot_generated_samples(samples)\n",
    "\n",
    "            # Compute score\n",
    "            z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "            samples = netG(z)\n",
    "            samples = (samples - samples.min()) * 2/(samples.max() - samples.min())  - 1\n",
    "            score = fdscore.calculate(samples)\n",
    "            print(\"Epoch = {e}, Score = {s}, D_real = {d}, D_fake = {g}\".format(e = epoch, s = score, d = D_real, g = D_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(netG, '1_dcgan_g.pth', confirm=False)\n",
    "    tools.save_model(netD, '1_dcgan_d.pth', confirm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40cc12a6e35bdd507142fe555e046e84",
     "grade": false,
     "grade_id": "cell-d7405a9598633d45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    nz = 10\n",
    "    netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    tools.load_model(netG, '1_dcgan_g.pth', device)\n",
    "    tools.load_model(netD, '1_dcgan_d.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96dd9d49b0c6c0379365d8a52beff292",
     "grade": false,
     "grade_id": "cell-b46c56d8c838b7b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## GAN evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af6a40216d030a310fab50a8e988954",
     "grade": true,
     "grade_id": "cell-e95aa3b7f714e6f9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(144, nz, 1, 1, device=device)\n",
    "        samples = netG(z)\n",
    "        torch.save(samples, '1_dcgan_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('1_dcgan_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "tools.plot_generated_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b861f66bf6a572406e1ca8d387c011dd",
     "grade": true,
     "grade_id": "test_quality",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the FD score\n",
    "torch.manual_seed(0)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples[:144])\n",
    "    score = fdscore.calculate(samples)\n",
    "\n",
    "print(f'FD score: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea9b31e0dfd137aa56d4b39623cf4b6c",
     "grade": true,
     "grade_id": "cell-23fa22d31962c3b9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14beeebf2cbd1a52db5c5d5ce6551fe4",
     "grade": false,
     "grade_id": "cell-37c0f19da39c5c9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this notebook, we learned how to train a simple GAN model for generating images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
